<!doctype html>
<html lang="zh-Hant">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>437｜试完GPT-4o画图，我第一次觉得人类设计师有点危险了</title>
</head>
<body>
<div class="article-cover-wrap"><img src="https://piccdn3.umiwi.com/img/202503/27/202503271356264586848734.jpeg"> <!----> <!----></div>

<div class="article-title iget-common-c1" style="-webkit-box-orient: vertical;">
    437｜试完GPT-4o画图，我第一次觉得人类设计师有点危险了
  </div>

<div class="article-info"><div class="author"><img src="https://piccdn3.umiwi.com/img/202405/25/202405251635229233825579.jpeg"> <span class="course-title iget-common-c3 iget-common-f4">
        快刀广播站
      </span></div> <span class="article-publish-time iget-common-c3 iget-common-f4">
      2025年3月28日 
    </span></div>

<div class="article-body"><div class="iget_rich-text-panel--container iget_rich-text-panel__large"><div class="editor-show" style="user-select: none; position: relative;"><div class="dd-audio" data-module-type="custom" style="z-index: 40; position: relative;"><div class="dd-audio-player iget-common-b7"><div class="dd-audio-info"><button class="dd-audio-icon iget-common-b10"><span class="iconfont iget-common-f4 iget-icon-play"></span></button> <div class="dd-audio-block iget-common-c2 iget-common-f5"><span class="audio-title" style="-webkit-box-orient: vertical;">试完GPT4o画图，我第一次觉得人类设计师有点危险了</span> <span class="audio-duration iget-common-c3 iget-common-f6">
          07分36秒
        </span></div></div></div> <div class="audio-tips iget-common-f4 iget-common-c3">
    转述师：AI
  </div></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">同学们，快刀广播站又开始广播了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">咱们AI学习圈的老同学都知道，在开圈第一天的直播里，我就给大家演示过怎么用AI生成图片。当时我还专门用Midjourney，给大家做了一批手机壳的图。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">不过不得不说，那时候AI画图的门槛还是挺高的。我的小本本上记了很多优秀的指令词，爱学习的我还坚持每天去官网，找一张别人做的图，去研究人家的指令词里有什么奥秘。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">但这种“背题库”式的努力，在AI飞跃之后，其实一下子就被抹平了。很快，大家就又回到了同一起跑线上。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我有这个感触，是因为<font style="color: rgb(255, 107, 0);">3月26号，OpenAI旗下的GPT-4o基础模型迎来了一次更新</font>。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">说实话，一开始我并没怎么在意。毕竟在OpenAI的产品里，不管是那款主打推理能力的o1，还是一个月200美金的o1Pro，关注度都远远盖过了4o。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">但这次4o最让我惊艳的，就是它的生图能力。我试用了一圈，跟大家说说我感受最深的地方。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><font style="color: rgb(255, 107, 0);">第一个，就是图的质量真的太逼真了。</font>我还专门翻出了2023年2月，自己第一次用AI生成的图片。当时我让它画一对80年代的青年男女，坐在广场上。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">最后出来的效果，用“惨不忍睹”来形容，都是在夸它。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我把图片放在了文稿中，你可以点开看看。</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025032721/1871622066844256048/032721.png" class="big-image"> <figcaption class="iget-common-c3 iget-common-b9 iget-common-f3">
    2023年AI作品
  </figcaption></figure> <!----><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025032721/1871622103350953776/032721.png" class="big-image"> <figcaption class="iget-common-c3 iget-common-b9 iget-common-f3">
    2025年AI作品
  </figcaption></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">转眼两年过去了，我用一模一样的指令词，让GPT-4o重新画了同样一张图。把两张图片放在一起一对比，你会有种恍然的感觉——原来AI在它自己的世界里，已经悄悄迭代了这么多。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><font style="color: rgb(255, 107, 0);">我的第二个感受是，现在中文也能直接生成在图上了。</font></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我以前经常建议大家在做海报的时候，用AI先画一个背景氛围图。但如果你想在图上加个标题或者口号，还得跑去美图秀秀或者Photoshop手动加文字。而这次4o直接就能在图上生成中文了。虽然偶尔会出点乱码，但大部分时候，文字都能准确地呈现出来。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">当我看到它能写中文的那一刻，我脑子里第一反应是：“要是我说一句话，它就能换个更好看的字体，那该多好。”你看，人类就是这么不知足。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><font style="color: rgb(255, 107, 0);">第三个感受是，现在可以直接把一张照片改成宫崎骏那种动漫风，或者换成别的风格。</font></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这两天你刷朋友圈，估计已经看到不少类似的动漫图了，那大概率就是用4o新模型做出来的。我也没忍住，拿了我和罗胖、脱不花的合影试了一下，效果挺有意思，放在文稿里了，大家可以看看。</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025032721/1871622129121276280/032721.jpeg" class="big-image"> <!----></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><font style="color: rgb(255, 107, 0);">第四个感受是，它现在可以一句话改图。</font></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这个功能真的是让我眼前一亮。因为GPT-4o的理解能力确实强，只要你把需求说清楚，它就能听懂、然后立刻开工。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我试了几个特别日常的场景，效果都很不错。比如，我扔一张图片进去，说“把衣服颜色改成蓝色”，它立马就换了；再比如，我扔两张图进去，说“合并一下”，它就直接给我融合成一张新图；还有一次，我拍了张办公桌的照片，让它把桌上的两个手办抠出来，它转头就给我做了一张带透明背景的图，只有那两个手办。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这就意味着，以后像做广告海报这种事儿，只要你说得明白，AI听得懂，那就能直接干，效率高得惊人。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><font style="color: rgb(255, 107, 0);">当然，AI也不是每次都能成功。</font></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">比如有一次，我让它把三个人的合影，全都换成阿根廷队服，它直接告诉我——这活儿有点难。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我就追问它为啥搞不定，它说这张图里三个人都穿着白衬衫，背景也是灰白的，要换得准确，有点费劲。然后它还特别认真地给我提了两个方案：一个是把三个人分别抠出来，单独换衣服，再合成回去；另一个是它先给我换一个人的衣服，发我看看效果，如果OK，它再继续换其他两个。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">说实话，看到它这套回复的时候，我真替不少不是特别出挑的设计师捏了把汗。我们先不说技术水平、工作速度，光是它这沟通能力，就已经把很多人类设计师比下去了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这次4o在生图上的进步，其实不全是AI自己变强了，更关键的，是背后有人类反馈强化学习在助力。OpenAI专门找了上百人的训练师团队，一起盯着AI生成的图，一个个去标注里面的错别字、失真的细节，或者那些畸形的手脚。然后再通过强化学习，不断地训练它，慢慢让AI学会怎么更精准地听懂人话、照着做事。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">说完这四大感受，我来说一下接下来可能产生的变化。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><font style="color: rgb(255, 107, 0);">第一个变化，是过去两年特别火的SD图像工作流，热度可能要慢慢降下来了。</font></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">以前像影楼、学校这种机构要用，成本高、上手难，门槛不低。但现在4o这个版本一出来，一些追求简单效果的AI智能体工作流，一下子就显得没那么必要了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">从这个细节来看，我们现在研究的AI工作流，其实也很可能只是个过渡方案。解决具体问题的小工具肯定还会有，但不一定非得用“工作流”这套复杂方式。因为现在，不管是在扣子还是其他地方做出来的那些智能体，更多还是偏个人用来自己玩、或者展示能力的，还很难真正嵌进企业的工作流程里去。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><font style="color: rgb(255, 107, 0);">第二个变化，就是对很多有想法的专业人士特别友好。</font></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">比如职场上要做一张海报、一个Logo，学校老师想画一张课件插图，或者做个物理实验的示意图，这些现在都可以直接交给AI来搞定。而且随着AI图像质量越来越高，我们也可以把画出来的图，继续扔进可灵、海螺这些AI视频工具里，让它们自动生成短视频。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我自己就试了一把——先让GPT-4o画了一张《桃花源记》洞口的画，然后把图扔进可灵，几分钟就变成了一段小视频。</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025032722/1871622235421192568/032722.png" class="big-image"> <!----></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><font style="color: rgb(255, 107, 0);">第三个变化，是很多项目在前期阶段，周期会被大大压缩。</font>不管是企业里的产品研发，还是广告公司的概念提案，现在每个人都可以先把自己的想法交给AI画出来，然后团队再一起看图讨论。这样一来，除了交流理念之外，还能激发出更多新的创意，效率也高了不少。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><font style="color: rgb(255, 107, 0);">第四个变化，是对那些写公众号的自媒体同学，真的太友好了。</font></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">以前光是找一张配图就得折腾半天，要是只是浪费点时间也就算了，最怕的还是用了不该用的图，还会被一些无良机构盯上、搞版权敲诈。但现在不一样了。你只要脑子里有画面，直接把想法描述给GPT-4o，它就能帮你画出来。如果你连画面感都没有，那就把你写的文字扔过去，让它根据内容自动配图。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这个场景我也亲自试过了，效果图放在了文稿里，大家可以自己感受一下。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我还特意翻了下自己的Midjourney账单，发现我第一次付费是2023年3月17日，10美金，到现在整整付了两年。但这次4o的更新，说实话，是我第一次认真动了“要不要退订Midjourney”的念头。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我脑子里一下就蹦出那句经典台词：“<font style="color: rgb(255, 107, 0);">以前陪我看月亮的时候，叫人家小甜甜；现在新人胜旧人了，叫人家牛夫人。</font>”</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">最后再说一件事，咱们AI学习圈这波AI产品好用榜评测已经接近尾声，最终榜单将在4月2日19:00正式发布。到时候，我和罗胖会一起开一场直播发布会，带大家一起揭晓这份亲测好用的AI工具榜单。这次，我们还开放了30个线下观众席位，欢迎你来现场，一起第一时间见证榜单发布、体验AI产品，还有机会现场交流、结识新朋友。感兴趣的同学，可以点击文稿区的链接报名，先到先得。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">报名链接：<a data-link="igetapp://activity/detail?ddurlMinVer=5.2.0&amp;url=https%3A%2F%2Fw.wjx.top%2Fvm%2FYJeanVM.aspx">https://w.wjx.top/vm/YJeanVM.aspx</a></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">好，今天广播就到这里。如果你觉得有帮助，欢迎分享转发给你的朋友。明天咱们接着聊AI。</p><div data-module-type="custom" class="split" style="z-index: 40; position: relative;"></div><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025032722/1871622397557780856/032722.png" class="big-image"> <!----></figure> <!----><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025032722/1871622434063435568/032722.jpeg" class="big-image"> <!----></figure> <!----><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto;"></div></div><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto;"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div></div><svg style="z-index: 20; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"></svg><svg style="z-index: 10; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"></svg><div style="position: absolute; width: max-content; text-align: center; line-height: 0; z-index: 50; transform: translate3d(-50%, -100%, 0px); transition: transform 0.2s, opacity 0.2s; visibility: hidden; opacity: 0;"><div class="em-menu" style="font-size: 12px; background-color: rgb(38, 38, 38); border-radius: 6px; color: rgb(221, 221, 221); border: 0px; display: inline-block; padding: 14px 5px; margin: auto; height: 66px; line-height: 66px; cursor: pointer;"><span class="em-menu-item" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>写笔记</span><span class="em-menu-item em-menu-item-select" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>划线</span><span class="em-menu-item em-menu-item-highlight" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-delete-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>删除划线</span><span class="em-menu-item em-menu-item-copy" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-copy" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>复制</span></div><div class="em-menu-triangle" style="margin: -1px auto 10px; border-top: 8px solid rgb(38, 38, 38); border-right: 8px solid transparent; border-left: 8px solid transparent; width: 0px; height: 0px;"></div></div></div></div></div>

<div class="article-time-info iget-common-c3 iget-common-f4"><!----> <div class="article-publish-time">
                  首次发布: 2025年3月28日 
                </div></div>
</body>
</html>
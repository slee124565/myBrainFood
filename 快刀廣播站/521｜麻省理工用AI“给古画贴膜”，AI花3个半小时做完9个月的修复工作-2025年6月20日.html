<!doctype html>
<html lang="zh-Hant">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>521｜麻省理工用AI“给古画贴膜”，AI花3个半小时做完9个月的修复工作</title>
</head>
<body>
<div class="article-cover-wrap"><img src="https://piccdn3.umiwi.com/img/202506/19/202506191427118965473424.jpeg"> <!----> <!----></div>

<div class="article-title iget-common-c1" style="-webkit-box-orient: vertical;">
    521｜麻省理工用AI“给古画贴膜”，AI花3个半小时做完9个月的修复工作
  </div>

<div class="article-info"><div class="author"><img src="https://piccdn3.umiwi.com/img/202405/25/202405251635229233825579.jpeg"> <span class="course-title iget-common-c3 iget-common-f4">
        快刀广播站
      </span></div> <span class="article-publish-time iget-common-c3 iget-common-f4">
      2025年6月20日 
    </span></div>

<div class="article-body"><div class="iget_rich-text-panel--container iget_rich-text-panel__large"><div class="editor-show" style="user-select: none; position: relative;"><div class="dd-audio" data-module-type="custom" style="z-index: 40; position: relative;"><div class="dd-audio-player iget-common-b7"><div class="dd-audio-info"><button class="dd-audio-icon iget-common-b10"><span class="iconfont iget-common-f4 iget-icon-play"></span></button> <div class="dd-audio-block iget-common-c2 iget-common-f5"><span class="audio-title" style="-webkit-box-orient: vertical;">麻省理工用AI“给古画贴膜”，AI花3个半小时做完9个月的修复工作.mp3</span> <span class="audio-duration iget-common-c3 iget-common-f6">
          07分43秒
        </span></div></div></div> <div class="audio-tips iget-common-f4 iget-common-c3">
    转述师：AI
  </div></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">你好，我是快刀青衣。欢迎收听快刀广播站，每天带你看AI。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">今天想跟大家聊一个AI落地的小众应用。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">不知道你有没有看过几年前那部特别治愈的纪录片——《我在故宫修文物》。其中有一个细节让我记忆特别深刻：古画修复师徐建华在修复一幅清代古画时，要进行一个叫“揭裱”的工序。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">镜头里，他一手抵着放大镜，一手用镊子以毫米为单位缓慢推进。每动一下，就要停顿一下，生怕不小心扯破那薄如蝉翼的画芯。徐师傅说，光是揭掉画背面旧裱这一道工序，就得花整整三天时间，而这只是整个修复流程中的一小步。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">当时看这些镜头，我几乎是屏住了呼吸，生怕自己在手机前的呼吸声都影响到他的动作。片中有一句台词，我至今还记得：“修复文物，其实是在修复时光的断层，让破碎的文明重新完整地呼吸。”</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025061922/1879416942859993388/061922.png" class="big-image"> <!----></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">最近我在权威学术期刊《自然》上看到一篇关于古画修复的研究论文，作者是麻省理工学院机械工程专业的研究生亚历克斯·卡奇金，论文标题叫做《利用数字构建的蒙版对古画进行物理修复》。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这个标题听起来有些专业，我来用更直白的方式解释一下。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">大家肯定都见过一些破损的古画或者老照片，会发现最大的问题在于——哪怕只是一张画，画面上的每一个小区域受损程度都可能完全不同。想要修复的话，必须一块一块地单独处理，往往是几百甚至上千个微小区域的工作量。所以在国外，完整修复一幅油画，动辄就要耗费几年甚至十几年的时间。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">而这项研究的做法，是结合了计算机视觉、图像识别和AI等多种技术，来快速生成一份这幅画作的“数字修复版本”。研究者把这份修复图稿打印在一层极薄的聚合物薄膜上，形成一个遮罩层，然后将其精准地对齐并贴合在原画表面。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">最终，原画加上这层“数字遮罩”，才共同构成了这幅古画的修复版本。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">并且因为这个遮罩层的数字源文件可以保存下来，供未来的修复人员参考，从而准确了解修复古画时做了哪些改动。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">大家如果看过《古董局中局》这类小说，可能会记得一个经典情节：一幅值钱的清朝古画，因为各种原因被揭开一层，结果发现里面还藏着一幅更值钱的唐宋古画。这个数字修复的方法，其实就是类似的原理——不是在宝贵的原画上动手，而是在上面加了一层蒙版，叠加之后，形成了一幅有修复效果的画作。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这种方法的好处也很直观。第一，心理压力小了，AI可以在蒙版上无限迭代，不用担心原画能不能承受；第二，效率也更高。在论文中，研究团队用这套方法修复了一幅严重受损的15世纪油画，AI自动识别出5612个待修复区域，并用上了57314种不同颜色填充，整个过程耗时只有3.5小时，比传统修复快了大约66倍。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>为什么作者会这么精确地说，比传统修复方法快了66倍？</b>那是因为这位论文作者从小就热爱艺术，修复古画是他一直坚持的副业。他专门学过传统的修复技法。在研究用AI做数字修复之前，他回忆说，自己几年前曾修复过一幅巴洛克风格的意大利油画，缺损程度和论文里的画差不多。那次修复他一共花了整整9个月的兼职时间才做完。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">所以其实可以看出，他是先遇到了这个痛点，才开始想办法用AI来解决问题的。在采访中他也反复强调：即使有了AI的加持，具体画作该怎么修，修成什么风格，仍然得由经验丰富的文物修复师来决定和把关。<b>AI更像是一个辅助工具，用来减轻体力劳动和时间成本，但绝不能取代人类专家对艺术风格和历史背景的判断。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这个项目在我看来，有一个特别大的好处，就是能“解锁”那些因为经费或人手不够而长期躺在库房里“吃灰”的受损艺术品，让它们以一种被修复的状态重新回到公众视野。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">在读这篇论文的过程中，我还注意到，作者引用了不少中国学者在古艺术保护与AI结合方面的研究成果。这也说明，<b>在这个艺术与AI融合的领域，咱们的研究者其实已经走在了前面。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">比如，南方科技大学在2020年发表的一篇论文，就被这篇论文的作者亚历克斯·卡奇金反复引用，引用了好几次。那篇论文的题目是《利用卷积神经网络和最近邻进行古画可控数字修复》。在看这篇论文的时候，有一个小细节让我印象挺深的，也给了我一些启发。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">估计有些对AI底层比较熟的同学，在看到这种项目时可能会有个疑问：那训练数据怎么来的呢？毕竟古画本身就很少，能拿来做AI训练的高精度数据就更少了，几乎不可能有大量一模一样的古画——一幅是损坏的，一幅是完好的——来让AI对比学习。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">所以，研究人员用了数据合成和迁移的方法。其中一个做法是，先收集大量完好的古画图像，或者风格接近的艺术画作，然后在图像上随机“挖洞”——当然，这个“洞”是打引号的。接着设置各种模拟损坏的形式，比如壁画剥落、缺角、斑驳、虫咬等等，让AI去尝试补全这些缺损的部分。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">最后，把AI补完之后的图像和原始图像进行对比，就能看出AI补得准不准，哪块偏了，哪块还原得好，这样就可以不断优化、反复迭代。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">在我们的这项研究里，虽然最终并没有生成一个真实的贴膜，贴在古画上进行物理修复，但这个数字修复项目在实际应用中已经发挥了很大的价值。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">首先，它可以在正式修复之前，由算法先生成多个修复方案，供文物修复师对比选择，从中挑出最符合史实和美学标准的那个版本。这样就能避免在原作上反复修复所带来的风险和不确定性。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">其次，即使有些艺术品损毁严重、暂时还无法进行实体修复，也可以通过数字方式“复原”，至少能在博物馆或线上展览中，让公众看到它们的原貌。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">不过最后，我忽然想起了一样东西，一件非常暴露年龄的回忆。在上世纪80年代中期，当时家家户户基本还都是12寸或14寸的黑白电视机。那个阶段市面上就出现了一个东西，叫“电视彩膜”，其实就是一张非常粗糙的塑料片，上面印着三种颜色，可以贴在电视屏幕上，让你感觉好像自己在看彩电。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">当然，它的显示效果和真正的彩电差得十万八千里，但对当时的我来说，那依然是一种非常震撼的体验提升。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">今天聊到的这两个关于古画修复的AI项目，其实也像是探索过程中的“彩膜”，可能不完美，但正在推动整个方向往前走。<b>正是因为这个世界上总有人愿意去研究这些看起来小众、不起眼的领域，AI才能逐渐渗透进我们生活的各个角落，最终像水、电、煤一样，成为未来的基础设施。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">最后，我也给自己主理的AI学习圈打个广告，今天是得到618大促返场期的最后一天了。年卡原价399元，现价369元。如果你之前就订阅了学习圈，觉得这个圈子对你用好AI有帮助，现在续费也是比较划算的，点击文稿区的活动链接就可以续费了，谢谢你继续支持我。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><a data-link="igetapp://activity/index?aid=6852d74ffcf3c1d4330b0bfb&amp;ddurlMinVer=9.11.0">点击参与AI学习圈年中返场活动</a></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">好，今天广播就到这里。如果你觉得有帮助，欢迎分享转发给你的朋友。明天咱们接着聊AI。</p><div class="article-header header-2" data-module-type="custom" style="z-index: 40; position: relative;"><span data-text-node="1">相关链接：</span></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">论文《使用数字构建的面具对绘画进行物理修复》https://www.nature.com/articles/s41586-025-09045-4</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">论文《利用卷积神经网络和最近邻进行古画可控数字修复》https://www.sciencedirect.com/science/article/abs/pii/S0167865520300787</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025061922/1879416984736177852/061922.jpeg" class="big-image"> <!----></figure> <!----><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto;"></div></div><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto;"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div></div><svg style="z-index: 20; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"></svg><svg style="z-index: 10; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"></svg><div style="position: absolute; width: max-content; text-align: center; line-height: 0; z-index: 50; transform: translate3d(-50%, -100%, 0px); transition: transform 0.2s, opacity 0.2s; visibility: hidden; opacity: 0;"><div class="em-menu" style="font-size: 12px; background-color: rgb(38, 38, 38); border-radius: 6px; color: rgb(221, 221, 221); border: 0px; display: inline-block; padding: 14px 5px; margin: auto; height: 66px; line-height: 66px; cursor: pointer;"><span class="em-menu-item" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>写笔记</span><span class="em-menu-item em-menu-item-select" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>划线</span><span class="em-menu-item em-menu-item-highlight" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-delete-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>删除划线</span><span class="em-menu-item em-menu-item-copy" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-copy" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>复制</span></div><div class="em-menu-triangle" style="margin: -1px auto 10px; border-top: 8px solid rgb(38, 38, 38); border-right: 8px solid transparent; border-left: 8px solid transparent; width: 0px; height: 0px;"></div></div></div></div></div>

<div class="article-time-info iget-common-c3 iget-common-f4"><!----> <div class="article-publish-time">
                  首次发布: 2025年6月20日 
                </div></div>
</body>
</html>
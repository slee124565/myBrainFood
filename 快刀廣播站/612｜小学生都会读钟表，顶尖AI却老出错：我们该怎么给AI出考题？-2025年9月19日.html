<!doctype html>
<html lang="zh-Hant">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>612｜小学生都会读钟表，顶尖AI却老出错：我们该怎么给AI出考题？</title>
</head>
<body>
<div class="article-cover-wrap"><img src="https://piccdn3.umiwi.com/img/202509/18/202509181123427959883444.jpeg"> <!----> <!----></div>

<div class="article-title iget-common-c1" style="-webkit-box-orient: vertical;">
    612｜小学生都会读钟表，顶尖AI却老出错：我们该怎么给AI出考题？
  </div>

<div class="article-info"><div class="author"><img src="https://piccdn3.umiwi.com/img/202405/25/202405251635229233825579.jpeg"> <span class="course-title iget-common-c3 iget-common-f4">
        快刀广播站
      </span></div> <span class="article-publish-time iget-common-c3 iget-common-f4">
      2025年9月19日 
    </span></div>

<div class="article-body"><div class="iget_rich-text-panel--container iget_rich-text-panel__large"><div class="editor-show" style="user-select: none; position: relative;"><div class="dd-audio" data-module-type="custom" style="z-index: 40; position: relative;"><div class="dd-audio-player iget-common-b7"><div class="dd-audio-info"><button class="dd-audio-icon iget-common-b10"><span class="iconfont iget-common-f4 iget-icon-play"></span></button> <div class="dd-audio-block iget-common-c2 iget-common-f5"><span class="audio-title" style="-webkit-box-orient: vertical;">小学生都会读钟表，顶尖AI却老出错：我们该怎么给AI出考题？.MP3</span> <span class="audio-duration iget-common-c3 iget-common-f6">
          10分36秒
        </span></div></div></div> <div class="audio-tips iget-common-f4 iget-common-c3">
    转述师：AI
  </div></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">你好，我是快刀青衣。欢迎收听快刀广播站，每天带你看AI。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">最近看到了一个有趣的AI测试，叫<b>ClockBench，专门测试AI读取模拟时钟的能力。</b>2025年9月，AI领域创业者兼研究员Alek Safar推出了这个视觉推理测试，这个测试并不复杂，甚至显得有些幼稚，仅仅是通过180个特制的模拟时钟和720道问题来对比人类与AI读取钟表的能力，但是最后的结果一下子震惊了业界。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我们先来看一下数据：<b>人类的平均准确率是89.1%，而参与测试的13个顶尖AI模型中，表现最好的Gemini 2.5 Pro也只有13.3%的准确率。</b></p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025091821/1887856149869447616/091821.png" class="big-image"> <!----></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">好家伙，这是什么概念？读钟表这事儿，在国内是幼儿园孩子都掌握的，甚至连穿着纸尿裤的人类幼崽都能轻松搞定的内容，结果那些在各种考试中吊打人类的AI，面对一个模拟时钟竟然直接蒙圈了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">更夸张的是，GPT-4o在这个测试中竟只拿到了2.1%，马斯克家的Grok 4更是垫底，仅有0.7%。这就好比让一个博士生去做小学数学题，结果却不及格。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">说实话，当我看到这个结果时，第一反应是：这些AI是不是故意装傻？毕竟它们在MMLU等综合知识测试中，早已接近甚至超越了人类专家的水平。难道它们是在扮猪吃老虎，隐藏自己的智力水平？</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">但仔细想想，如果AI真这么聪明，那就应该伪装成普通人的水平，而不是装大傻子。所以，背后可能藏着一个更深层的问题：<b>我们究竟该如何给AI设计考题？</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">其实，ClockBench只是<b>“人类容易，AI困难”</b>这类测试中的一个典型代表。类似的例子还有不少，每一个都令人大跌眼镜。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">先说<b>ARC-AGI</b>，这个被称为<b>“当前世界上最重要的未解决AI基准”</b>的测试。它专门考查AI识别模式和解决新问题的能力，用的都是一些看起来很简单的网格图形推理任务。结果呢？GPT-2得了0分，GPT-3仍然是0分，GPT-4好不容易拿到了2分，而GPT-4o也只有5分。直到o1-preview，才勉强达到21分。我在下方放了考题的截图，你一下子就能明白是什么任务了。</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025091819/1887847257140122132/091819.png" class="big-image"> <!----></figure> <!----><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025091819/1887847263582636480/091819.png" class="big-image"> <!----></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">当然，这个测试图形是他们的二代考题，他们现在正在设计第三代考题，计划让AI玩几种不同的电脑游戏，来测试它们的推理和反应能力。他们原计划在8月份推出第一个游戏的测试结果，不过我在官网上还没有看到，这个我会持续关注。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">但是你想想，这些在各种专业考试中能表现超群的AI，面对一些小学生都能看懂的图形推理题，居然连及格线都摸不到。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我们再来看另一个测试，<b>SimpleBench。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>这项测试专门挑选了一些人类日常生活中的简单推理题，</b>比如“想象一下，如果你把一盘蔬菜倒过来会发生什么？盘子里还有多少蔬菜？”这种问题，<b>普通人一眼就能看出答案，但AI模型的表现却依然让人大跌眼镜。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">还有一道更绝的题：“贝丝在第一分钟开始时在煎锅里放了四块完整的冰块，第二分钟开始时放了五块，第三分钟开始时又放了一些，但第四分钟没有放一块完整的冰块。如果煎脆皮鸡蛋时，平均每分钟放入锅中的冰块数量为五块，那么第三分钟结束时锅里有多少块完整的冰块？”</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">看到这道题，我的第一反应是：谁会在煎鸡蛋的时候往锅里放冰块？但仔细想想，这恰恰是这类测试的精髓所在——<b>它们故意设置一些看似荒谬但逻辑清晰的场景，来测试AI能不能像人类一样进行常识推理。</b>感兴趣的同学，也可以去试试这个测试，答对了，你可以骄傲地说你是人类；答错了，你也可以自豪地说自己和很多顶级AI水平相当。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">反正我用这道题测试了豆包和ChatGPT，它们都一本正经地给我做数学题，一步步告诉我计算结果是什么。我把截图也贴在了下方，你看了就知道，有个很扎心的形容词叫“清澈的愚蠢”，大概也就是这样了。当然，这个测试也有个特别不好的地方，就是打开他们的官网SimpleBench，首字母是一个S，一个B，放在浏览器里看起来特别像是在骂人一样。</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025091819/1887847304384825792/091819.png" class="big-image"> <!----></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">回到我们刚才说的这些测试，从这结果就能看出很有意思了。AI在背书、做题、写代码方面已经超神，但一遇到这些需要常识和直觉的任务，立马就原形毕露了。就像一个书呆子，理论知识倒背如流，但让他在现实生活中解决一个简单问题时，反而束手无策。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">那么问题来了：<b>为什么传统的AI基准测试对现在的AI来说越来越“没用”了？</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">说实话，这事儿早就有征兆了。看看<b>MMLU，这个曾经的“金标准”测试</b>，涵盖57个学科的15,908道题，从人文到理工科应有尽有。几年前GPT-3在上面只拿到43.9%，大家都认为还有很大进步空间。结果到了GPT-4，得分直接飙升到86.4%，接近人类专家的90%这一水平。现在的顶尖模型基本都在86-91%这个区间里竞争，差距已经很小了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>这就是研究者所说的“基准饱和”现象。</b>就像高考试题被刷烂了一样，AI模型在这些传统测试上的表现已经接近天花板，进一步提升的空间很有限。<b>更要命的问题其实是“测试污染”。</b>一旦某个基准测试被广泛使用，AI研究者就会针对这个测试优化模型。所以表面上看分数提高了，但模型的真实能力未必有实质性突破。就像应试教育一样，学生考试成绩很高，但解决实际问题的能力可能还是有限。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">当然，这里还有一个更深层的问题：<b>传统测试大多基于“记忆+检索”的模式。</b>例如，问“拿破仑是哪年称帝的？”这种问题，只要训练数据里有，AI就能答对。<b>但是现实世界的问题往往需要“理解+推理”</b>，需要你真正明白事物之间的关系，而不是简单地背答案。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">那么，新时代该怎么给AI出考题呢？从我们今天看到的ClockBench这些测试的设计中，我们能看出一些门道。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>首先，好的AI测试必须是“防作弊”的。</b>ClockBench使用了36种全新设计的表盘，180张从未在网上出现过的时钟图片，这样AI就没法靠“背题”来蒙混过关，必须真正理解什么是时钟，什么是指针。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>其次，测试内容要贴近真实场景。</b>读时钟、识别卫生间标识、规划路线，这些都是我们日常生活中会遇到的真实问题。不像传统测试那样考一些脱离实际的理论知识，而是真正考验AI能不能在现实世界中帮到我们。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第三，要测试“泛化能力”，而不是“记忆能力”。</b>ARC-AGI为什么这么难？因为它测试的是AI能不能从少量示例中快速学会新规则，然后应用到从未见过的情况中。这就像人类的学习过程——我们不需要看遍所有的三角形，就能理解什么是三角形。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>最有意思的是，这些新测试还采用了“动态更新”机制。</b>一旦某个测试被AI“攻克”了，就立马更新题目，保持测试的挑战性。这就像一个永远在进化的考官，不会让学生有机会“刷题”。说到底，所有这些测试都有一个共同目标：<b>不是为了证明AI有多笨，而是为了找到AI的能力边界，知道它们在哪些方面还需要改进。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">不过，对于我们普通人来说，<b>最重要的其实不是这些“官方考试”，而是要学会给AI出属于自己的考题。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这就像小马过河的故事。老牛说水很浅，松鼠说水很深，但只有小马自己下水试了，才知道水到底有多深。<b>面对AI也是一样，别人说它有多强或多弱，都不如你亲自测试一下来得实在。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我前段时间在广播站里，也和你分享了我的一个测试，就是用几个AI工具来识别男女卫生间标识，结果让人哭笑不得。有一些很知名的模型，在识别男女卫生间标识上，还经常出错。要知道，这可不是回答一个文学题或者数学题，这个题答错了是真的会被人打出来，甚至会被扭送到派出所。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">还有一个关键是，你的需求和别人的需求很可能不一样。也许你需要AI帮你写代码，也许你需要它帮你分析数据，也许你就是想让它陪你聊天解闷。不同的需求，对AI能力的要求完全不同。那些在学术基准上表现优异的模型，未必就适合你的具体场景。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">所以，<b>与其纠结哪个AI在某个权威测试中得了多少分，不如花点时间设计几个针对自己需求的小测试。</b>比如，如果你想用AI来写工作邮件，就找几封你之前写过的邮件，让不同的AI重写一遍，看看哪个更符合你的风格；如果你想用AI来做数据分析，就拿一个你熟悉的数据集，看看哪个AI能给出更有价值的洞察。这种“私人定制”的测试，比任何权威基准都更有参考价值，因为它直接关系到AI能不能真正帮到你，而不是能不能在某个抽象的测试中拿高分。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">说白了，<b>AI时代最重要的技能之一，就是学会当自己的“考官”。</b>不要被那些花里胡哨的基准测试数据迷惑，也不要盲信别人的推荐。<b>最靠谱的方法，永远是亲自下水试试深浅。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">好，今天广播就到这里。如果你觉得有帮助，欢迎分享转发给你的朋友。明天咱们接着聊AI。</p><div data-module-type="custom" class="original-block-quote" style="z-index: 40; position: relative;"><blockquote data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line;"><b>相关链接：</b><br>1. Simple Bench：<br>https://simple-bench.com/try-yourself<br>2. ARC-AGI：<br>https://arcprize.org/arc-agi/2/</blockquote></div> <!----> <!----><div data-module-type="custom" class="split" style="z-index: 40; position: relative;"></div><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025091819/1887847378472423956/091819.png" class="big-image"> <!----></figure> <!----><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto;"></div></div><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto;"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div></div><svg style="z-index: 20; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"></svg><svg style="z-index: 10; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"></svg><div style="position: absolute; width: max-content; text-align: center; line-height: 0; z-index: 50; transform: translate3d(-50%, -100%, 0px); transition: transform 0.2s, opacity 0.2s; visibility: hidden; opacity: 0;"><div class="em-menu" style="font-size: 12px; background-color: rgb(38, 38, 38); border-radius: 6px; color: rgb(221, 221, 221); border: 0px; display: inline-block; padding: 14px 5px; margin: auto; height: 66px; line-height: 66px; cursor: pointer;"><span class="em-menu-item" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>写笔记</span><span class="em-menu-item em-menu-item-select" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>划线</span><span class="em-menu-item em-menu-item-highlight" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-delete-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>删除划线</span><span class="em-menu-item em-menu-item-copy" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-copy" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>复制</span></div><div class="em-menu-triangle" style="margin: -1px auto 10px; border-top: 8px solid rgb(38, 38, 38); border-right: 8px solid transparent; border-left: 8px solid transparent; width: 0px; height: 0px;"></div></div></div></div></div>

<div class="article-time-info iget-common-c3 iget-common-f4"><!----> <div class="article-publish-time">
                  首次发布: 2025年9月19日 
                </div></div>
</body>
</html>
<!doctype html>
<html lang="zh-Hant">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>456｜专访科技观察家卓克：DeepSeek带来4大冲击波，AI模型训练不再靠参数</title>
</head>
<body>
<div class="article-cover-wrap"><img src="https://piccdn3.umiwi.com/img/202504/15/202504151055165332849320.jpeg"> <!----> <!----></div>

<div class="article-title iget-common-c1" style="-webkit-box-orient: vertical;">
    456｜专访科技观察家卓克：DeepSeek带来4大冲击波，AI模型训练不再靠参数
  </div>

<div class="article-info"><div class="author"><img src="https://piccdn3.umiwi.com/img/202405/25/202405251635229233825579.jpeg"> <span class="course-title iget-common-c3 iget-common-f4">
        快刀广播站
      </span></div> <span class="article-publish-time iget-common-c3 iget-common-f4">
      2025年4月16日 
    </span></div>

<div class="article-body"><div class="iget_rich-text-panel--container iget_rich-text-panel__large"><div class="editor-show" style="user-select: none; position: relative;"><div class="dd-audio" data-module-type="custom" style="z-index: 40; position: relative;"><div class="dd-audio-player iget-common-b7"><div class="dd-audio-info"><button class="dd-audio-icon iget-common-b10"><span class="iconfont iget-common-f4 iget-icon-play"></span></button> <div class="dd-audio-block iget-common-c2 iget-common-f5"><span class="audio-title" style="-webkit-box-orient: vertical;">专访科技观察家卓克：DeepSeek带来4大冲击波，AI模型训练不再靠参数</span> <span class="audio-duration iget-common-c3 iget-common-f6">
          15分55秒
        </span></div></div></div> <div class="audio-tips iget-common-f4 iget-common-c3">
    转述师：AI
  </div></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">你好，我是快刀青衣。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">欢迎收听快刀广播站，每天带你看AI。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">今天，咱们继续做2025年一季度AI大事盘点，聊聊一线从业者或者观察家眼中，过去3个月AI领域发生的真正重要的变化。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这期分享，我请到了得到同学都很熟悉的《科技参考》的主理人，卓克老师。卓克老师一直追踪科技领域的前沿变化，他特别擅长把那些看起来很复杂的技术趋势拆解明白，然后告诉大家：它会如何影响普通人的生活。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">为了这次的季度观察，我专门请教了他3个问题：</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">2025年一季度，你眼中AI领域最重要的那件事儿是什么？你对2025年AI的发展有什么预测？作为普通人，我们该如何行动？</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">接下来我就来为你转述一下，卓克老师对2025年AI技术趋势的观察。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><br></p><div data-module-type="custom" class="split" style="z-index: 40; position: relative;"></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><br></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">你好，我是卓克。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这次受得到联合创始人快刀老师邀请，我就从一个科技观察者的视角来分享一下，我对今年一季度AI的几个观察思考。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">在进入正题之前，我想跟你分享一个自己的故事，是我作为一个从AI照猫画虎开始学人说话时就开始接触AI的人，过去两年被AI震撼到的那个瞬间。</p><div class="article-header header-1" data-module-type="custom" style="z-index: 40; position: relative;"><span data-text-node="1">一、AI带给我震撼的时刻</span></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">那是2024年9月，OpenAI的o1模型刚上线的时候。那阵子我正好在琢磨一个跟禽流感有关的问题，正巧赶上它上线，我就想着试试它到底有多厉害。我一直搞不清楚为什么那么多病毒都叫H1N1，它们到底有什么不同。那天孩子妈带着孩子出去玩，我一个人在家煮面，用语音输入的问题，一连问了好多。o1特别厉害，几乎每个疑问它都能回答，而且还给了准确的参考资料。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">不过，有一个细节它一直没说清楚。我追问了几次，它像是突然“意识到”我真正困惑的地方，然后一下子给我讲了很多我需要的细节。那一刻，我的感觉已经不能用“豁然开朗”来形容了，更像是本来堵得死死的下水道，突然哗啦一下通了的那种痛快。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">说实话，这种感觉我上学的时候从来没体会到过，因为之前要不就是书本直接告诉我，要不我自己要花很多时间，反复对比才能慢慢想出来。而o1就像一下看穿了我卡在哪儿，一针见血地解决了我的问题。那一刻，我真觉得世界上最懂我的就是o1了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">不过，AI就是一个日新月异的东西，震撼时刻随时都有可能出现。如果说o1是带推理功能的AI，在世界范围内的首次亮相，那么今年，它的风头已经完全被另一个名字盖了过去，那就是DeepSeek。</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025041519/1873374986878633776/041519.png" class="big-image"> <figcaption class="iget-common-c3 iget-common-b9 iget-common-f3">
    DeepSeek R1推理模型
  </figcaption></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">2025年年初，DeepSeek横空出世，几乎是凭一己之力让全民都用上了AI。如果说之前，AI可能还是少部分人的工具，但是DeepSeek出来之后，家里的长辈、小孩，起码中国现在很多70岁以上的老年人都知道了它。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">正如我使用o1时的体验一样，DeepSeek带来的冲击是巨大的，对国内外的冲击都很大。冲击的核心在于，AI使用成本下降了一个数量级，所以很多事情的逻辑变了。下面我挨个说一说。</p><div class="article-header header-1" data-module-type="custom" style="z-index: 40; position: relative;"><span data-text-node="1">二、DeepSeek掀起的4个冲击波</span></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">首先说说对AI小公司的影响。我的观察是，<b>今年DeepSeek已经把很多小公司逼上了绝路，钱必须花在刀刃上了。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我这里说的“小公司”，其实在很多人眼里已经不算小了。比如大家熟知的“AI六小虎”：智谱、MiniMax、月之暗面、百川智能、零一万物、阶跃星辰，还有一些比它们规模更小的AI创业公司。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">目前，这些AI小公司一个共同的难题是：还没有实现“自我造血”——也就是说，虽然他们自己研发了大模型，但靠用户付费来维持运营、实现盈利这件事，谁都还没做到。不管是做订阅、卖授权，还是通过App或API收费，现在离真正靠产品赚钱、养活自己的目标还差得挺远。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">所以这些小公司普遍的做法，就只能通过拼“用户数据”来吸引投资人，比如用户数、月活跃度等等。这就需要砸钱做营销，在微博、微信、小红书这些平台上拉流量、做曝光。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">但今年年初，DeepSeek的出现打破了这个逻辑。它不仅产品好、速度快，还免费开放，对用户来说吸引力太大了，搞得很多小公司连用户增长都变得困难，别说靠用户收费了。用户和活跃度这些“指标”，也被DeepSeek抢去了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这样一来，小公司也不再烧钱搞大规模推广了。下一轮融资时，想打“我们要买算力卡训练模型”的牌，也没那么有说服力了——因为DeepSeek已经证明：训练成本可以压到原来的十分之一。这种情况下，谁还愿意投一大笔钱去支持你重复造轮子呢？</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我看到的现实情况是，“六小虎”里已经有两家公司放弃了开发更大模型的计划。原因很简单——太烧钱了。他们现在转而尝试把现有模型打磨成真正有用的产品，希望能够吸引用户或企业买单，实现变现。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">但难点在于，用户那边已经有大公司免费提供的好模型可用了，有实力的企业也早就自己部署了像DeepSeek R1这样的模型，不可能再花几百万买小公司的模型了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这么一来，小公司可能就剩了一条出路——被大公司收购。但在等待被收购的这段时间里，最重要的是别把手里的钱烧光，要尽可能保留“人才优势”，把团队和技术能力秀出来，因为这可能是大公司愿意买下你的核心理由。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>说完小公司，再来说说大公司受到的冲击。</b>这里我所说的“大公司”，指的是过去十年就已经是互联网巨头的企业，比如豆包背后的字节跳动、文心一言背后的百度、通义千问背后的阿里等。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>对他们来说，我的观察是，用DeepSeek V3和R1的研发思路来搞自己的模型，今年成了一个必选项。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">相比前面说的AI小公司，大公司因为有其他业务反哺AI模型研发，所以不会太着急立刻通过AI赚钱。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">但他们面临的“终极任务”是：怎么做出一个用户愿意为之掏钱的AI产品，并且有DeepSeek免费开放使用在前，大公司的AI产品，定价不可能太高，这意味着产品起码在提供AI推理服务的时候，成本必须尽量压低。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">为了做到这一点，这些大公司必须要“重新训练模型”。什么意思呢？就是说他们把以前自己研发的大模型重新训练一遍，采用一种叫“混合专家模型”（MoE）的新结构。这种结构的好处是：每次运行AI的时候，只需要激活其中5%左右的模型参数，能大大降低计算量。</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025041519/1873375116801394480/041519.png" class="big-image"> <figcaption class="iget-common-c3 iget-common-b9 iget-common-f3">
    DeepSeek V3和R1都用了MoE架构
  </figcaption></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">另外，他们还用上了“多头注意力低精度优化”（MHLA），这个技术能大幅度减少显存占用，让AI在运行时更节省资源——特别适合他们自己采购的“缩水版”算力卡（比如H20这种性能被砍了一刀的卡）。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">除此之外，还有另外两个关键技术：FP8混合精度和Dualpipe（双通道并行），这些也都是为了进一步提升运行效率、降低成本。如果不用这些技术，就很难在AI的竞赛中跟其他巨头抗衡。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">所以现在我们可以看到一个趋势：虽然大公司入场晚，但最后往往是他们“打扫战场”——他们把模型产品化、做好体验、铺好渠道，才是最后真正能赚到钱的。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">他们接下来要解决的问题也很现实：除了做一个聊天机器人能陪你聊两句，或者做一个比百度搜索质量高100倍的“超级搜索工具”，还有没有别的AI服务，是用户真的“非用不可”，而且愿意掏钱买的？</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">又或者，他们原本就有很多App，那些App里有没有哪一些功能结合AI之后，能让用户更爱用、留得更久，甚至吸引更多新用户？毕竟，巨头每年在AI上的投入也不少，到头来还是得想办法把这笔钱挣回来。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>对投资人来说，变得更冷静务实。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">投资人现在终于冷静下来了。以前一听说是“自研模型”，很多人就抢着投钱，完全不问能不能赚钱。现在大家开始认真算账了：这个东西到底能不能实现商业变现？而现实是——基本没人能轻松赚钱，就连OpenAI每天都在亏钱。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我一直很佩服这些投资人，也觉得我们应该感谢他们。因为有他们的支持，AI技术才能不断进步，使用成本也在不断下降。可以预见的是，未来每百万token的收费还会一阶阶往下调。但说实话，除了极少数可能被大公司收购的AI企业，其他很多投资，恐怕最后都是血本无归。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>对消费者来说，更好的性能，更低的价格，甚至免费的AI服务越来越多。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">不过，在这个过程中真正“赚到”的，是我们这些用户。比如我现在有一个很复杂的问题，我会同时问六个平台，其中只有两个是收费的。五年前，要完成同样的事，我可能得雇两个研究生来帮我，现在只需要花一千多块钱一个月，我就能搞定，真的特别满足。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我算是个AI的老用户了。最开始接触的AI学人说话学得还不太像。过了几个月，AI才开始说得稍微像回事。又过了一年多，它才突然学会了推理分析。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">你再想想，2024年1月28日，大家还都在用那种“没脑子”的语音助手（比如Siri）；结果今年1月就突然冒出来一个AI，能理解你的需求，还能整理分析内容，做得有模有样。对很多人来说，那一刻真的就是“神奇”。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">尤其是中国，连很多70多岁的老人现在都知道AI有这些厉害的功能。像我爸妈、叔叔、婶婶、大姑这些亲戚，全都知道。这说明什么？说明AI已经有了很广泛的群众基础，而这也是未来AI人才出现的土壤。</p><div class="article-header header-1" data-module-type="custom" style="z-index: 40; position: relative;"><span data-text-node="1">三、2025预测：AI模型训练的参数竞赛宣告结束</span></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>从技术角度来说，AI现在最重要的变化是：拼谁的模型更大、参数更多的比赛，基本已经停下来了。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">目前和GPT-4.5一起竞争的基础模型，可以说是最后一代“大模型”。除了GPT-4.5，还有刚刚发布的Llama 4。虽然OpenAI没公开GPT-4.5的具体参数数量，但参考GPT-4已经有1.8万亿参数，很多人猜测GPT-4.5可能在3到5万亿之间。</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025041519/1873375302558724472/041519.jpeg" class="big-image"> <figcaption class="iget-common-c3 iget-common-b9 iget-common-f3">
    Meta开源的Llama4大模型
  </figcaption></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">GPT-4.5发布后，大家的反应普遍都不好，甚至差评一片。原因是它的表现比一年前的o1模型还要差。其实o1是在GPT-4的基础模型上，加上“思维链”技术优化出来的。而GPT-4.5不但性能不佳，价格还特别贵。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">举个例子：同属一个时代的Claude 3.7模型，输出1M token的价格是15美元，而GPT-4.5却要150美元；输入方面，Claude 3.7是3美元，GPT-4.5却是75美元。也就是说，GPT-4.5的价格是对手的10倍到25倍，但性能还不如对方。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">价格这么贵，主要是因为参数太大，导致运行一次所需要的算力成本太高。这就成了个“费力不讨好”的局面。其实在GPT-4.5发布之前，行业里就普遍认为，继续扩大模型参数带来的效果已经很有限了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">而GPT-4.5的发布，正好就像是个“警示牌”一样：我把模型搞大了好几倍，优化也没做到位，结果给大家看看——还不如上一代。那你们还要继续学我吗？</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">Llama 4的情况也不太好。它虽然把知识更新到了2024年9月，但一直拖到2025年4月的某个周末才发布，让人怀疑是不是看到OpenAI推出了带推理能力的o1，Meta那边被震住了，又重新调整了半年多。等到发现GPT-4.5表现不行，才决定把自己的模型也上线。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">不过，目前还有一些“万亿参数级别”的大模型仍在训练中，它们当然也会继续做完。因为这些模型不仅仅是扩大了规模，还进入了多模态训练，也就是说，不只是用文字训练，还加入了视频、音频、图片等内容。这和以前只训练文字的模型，还是有本质差别的。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">但等这一代模型训练结束，如果训练方法不出现重大变化的话，大语言模型在参数规模上的“天花板”就已经到了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">接下来的发展重点，将不再是“把模型做得更大”，而是围绕“混合专家模型”和“强化学习结合思维链技术”来提升智能。这条技术路径，我们其实已经在DeepSeek R1模型里看到了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>从AI的应用场景来看，我们现在能观察到两个明显的变化。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">第一个变化是具备推理能力的产品已经成为标配。各家公司都在推出类似Deep Research这样的产品，也就是可以自主调研、分析复杂问题的工具。由于基础大模型的性能在参数量不再增长的情况下提升空间有限，因此增强推理能力就成了唯一的突破口。比如OpenAI用GPT-4开发出了o1和o3，其中o3被打造成了一个智能代理，也就是我们现在用的Deep Research。我估计到2025年，其他公司也会陆续推出多个类似版本。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">第二个变化是“原生多模态”的大模型会变得非常普遍。它们能够直接生成高质量的音频、视频和图像。2024年年初，很多人在看到OpenAI的Sora时都觉得非常惊艳，虽然其中也有一定的营销和美化成分。实际情况是，Sora发布后的一整年里才有产品真正落地。而到了2025年，各大AI平台推出的视频生成功能，几乎都能轻松超越当年Sora的水平。比如OpenAI基于GPT-4o推出的图像生成功能，就是通过训练原生多模态的模型实现的。随着这种生成能力不断提升，大家也会慢慢习以为常。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">当然了，在走向习以为常甚至变得麻木的这个过程中，还是会有不少人担心自己的工作被AI取代。或者我们换个表述方式，<b>当AI在悄悄接手人类的工作时，我们该做点什么准备？</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我想说的是，虽然AI的能力在越变越强，但是今天AI依旧存在很多功能上的短板。比如，它还没法处理一些特别复杂的任务。比如做一场跨年演讲，或者自己剪辑完成一整部动画片。还有一点很关键，AI现在还不能主动理解你的需求。比如说最吸引我的是那些我不知道我哪里不知道，并且有意思的东西。我的需求是能不能给我梳理梳理，每天给我讲15分钟？</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">以上这几个任务，今天的AI都做不到，而且今后很长一段时间AI也做不到，为什么？其实跟AI的上下文长度限制有关系。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">现在最厉害的AI，能处理大概50万个token（也就是语言单位），甚至100万个token。这个长度已经可以让它一口气翻译一部小说，不需要分段处理。但即便如此，它依然搞不定上面说的那几个任务。因为像动画片、演讲策划、主动发现兴趣点这种任务，需要非常庞大的信息做参考——远远超过了当前AI能处理的token上限。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">所以我们该怎么做呢？就是要去做那些，哪怕AI可以处理一部分内容，但如果真正完整执行下来会远远超出它能力范围的事情。也就是说，那些需要处理的信息量远超100万个token的复杂任务。只要我们在这些领域深耕，就不会轻易被AI取代。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><br></p><div data-module-type="custom" class="split" style="z-index: 40; position: relative;"></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><br></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">好，以上就是卓克老师今天的分享。如果你听完之后觉得有帮助，欢迎你把这篇文章分享给你身边正在做AI、或者想转型到AI领域，对AI技术前沿感兴趣的朋友。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">再剧透一下，明天的广播站将请到Beta硅谷智库创始人云飞老师，他将从投资人的一线视角，分享2025年一季度他看到的硅谷AI行业的最新变化，和他给你我这样的普通个体的2个行动建议。记得准时来看。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">最后的最后，提醒一下，只要你是AI学习圈的会员同学，都可以免费领取AI学习圈2025春季特刊。我在文稿里放了一张路径截图，你可以在AI学习圈首页下方的【圈子热点】里领取。</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025041519/1873375492611588432/041519.jpeg" class="big-image"> <!----></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">好，今天广播就到这里。明天咱们接着聊AI。</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025041519/1873375511938416976/041519.png" class="big-image"> <!----></figure> <!----><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto;"></div></div><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto;"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div></div><svg style="z-index: 20; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"></svg><svg style="z-index: 10; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"></svg><div style="position: absolute; width: max-content; text-align: center; line-height: 0; z-index: 50; transform: translate3d(-50%, -100%, 0px); transition: transform 0.2s, opacity 0.2s; visibility: hidden; opacity: 0;"><div class="em-menu" style="font-size: 12px; background-color: rgb(38, 38, 38); border-radius: 6px; color: rgb(221, 221, 221); border: 0px; display: inline-block; padding: 14px 5px; margin: auto; height: 66px; line-height: 66px; cursor: pointer;"><span class="em-menu-item" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>写笔记</span><span class="em-menu-item em-menu-item-select" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>划线</span><span class="em-menu-item em-menu-item-highlight" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-delete-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>删除划线</span><span class="em-menu-item em-menu-item-copy" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-copy" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>复制</span></div><div class="em-menu-triangle" style="margin: -1px auto 10px; border-top: 8px solid rgb(38, 38, 38); border-right: 8px solid transparent; border-left: 8px solid transparent; width: 0px; height: 0px;"></div></div></div></div></div>

<div class="article-time-info iget-common-c3 iget-common-f4"><!----> <div class="article-publish-time">
                  首次发布: 2025年4月16日 
                </div></div>
</body>
</html>
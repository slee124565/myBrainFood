<!doctype html>
<html lang="zh-Hant">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>530｜周日荐文：AI学会反思后智商飙升，分享我训练AI干活的3个方法</title>
</head>
<body>
<div class="article-cover-wrap"><img src="https://piccdn3.umiwi.com/img/202506/28/202506280707067680361616.jpeg"> <!----> <!----></div>

<div class="article-title iget-common-c1" style="-webkit-box-orient: vertical;">
    530｜周日荐文：AI学会反思后智商飙升，分享我训练AI干活的3个方法
  </div>

<div class="article-info"><div class="author"><img src="https://piccdn3.umiwi.com/img/202405/25/202405251635229233825579.jpeg"> <span class="course-title iget-common-c3 iget-common-f4">
        快刀广播站
      </span></div> <span class="article-publish-time iget-common-c3 iget-common-f4">
      2025年6月29日 
    </span></div>

<div class="article-body"><div class="iget_rich-text-panel--container iget_rich-text-panel__large"><div class="editor-show" style="user-select: none; position: relative;"><div class="dd-audio" data-module-type="custom" style="z-index: 40; position: relative;"><div class="dd-audio-player iget-common-b7"><div class="dd-audio-info"><button class="dd-audio-icon iget-common-b10"><span class="iconfont iget-common-f4 iget-icon-play"></span></button> <div class="dd-audio-block iget-common-c2 iget-common-f5"><span class="audio-title" style="-webkit-box-orient: vertical;">AI学会反思后智商飙升，分享3种我训练AI干活儿的方法</span> <span class="audio-duration iget-common-c3 iget-common-f6">
          11分55秒
        </span></div></div></div> <div class="audio-tips iget-common-f4 iget-common-c3">
    转述师：AI
  </div></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">你好，我是快刀青衣，欢迎收听快刀广播站，每天带你看AI。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">今天想跟大家分享一篇AI领域的技术论文。同学们别一听“技术论文”这四个字就立刻产生畏难情绪，觉得高深莫测、难以理解，然后干脆关掉退出了。放心，我会尽量用通俗易懂的语言，把这篇论文的核心观点给大家讲清楚。</p><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025062815/1880224102506114488/062815.png" class="big-image"> <!----></figure> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我先说说自己是怎么发现这篇论文的。熟悉AI的同学大多知道一个网站叫Hugging Face，这个平台不仅有各种大模型的训练场和技术讨论区，还开设了一个“每日论文”栏目。由于AI领域如今太过火热，每天都有大量新论文发布，这个栏目就像是一个论文版的“知乎热榜”——作者提交论文，读者点赞排名。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我今天要介绍的这篇论文，就是这个栏目6月榜单中排名第三的一篇，名字有点长，叫<b>《反思，重试，奖励：通过强化学习实现自我改进的大语言模型》</b>。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">顺便说一句，我之所以没有选排在前两名的论文，是因为前两篇都更偏底层技术，与我们平时的使用距离太远。排名第一的是关于咱们国产模型MiniMax的技术论文。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">回到今天要介绍的论文，作者并不是一个典型的高校研究学者，而是一家名叫Writer的人工智能创业公司的研究团队，联合作者一共有八个人。也许正因为是创业企业的研究团队，所以没有那么在乎学术层面的论文惯例，整个论文加上引用也只有16页，读起来也没有故作高深，非常简单明了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我刚才念了一遍这篇论文的题目，其实就已经把最核心的观点说完了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">在我们人类的学习过程中，“从错误中学习”是非常重要的一环。不信你去网上搜搜看，文具有一个专门的品类就叫“错题本”。我们在求学时，当一道题没做对的时候，好的老师肯定不会直接说答案，而是会引导我们反思，“你觉得问题出在什么地方？下次可以怎么改进？”</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">而这篇论文的核心研究，就是提出了一种巧妙的方法，<b>让AI能像人一样，从错误中不断成长。</b>研究团队发现，即便是再强大的模型，也存在自己的“盲区”——它在某一个任务上表现得非常好，但并不代表它就一定能顺利搞定类似的另一个任务。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">面对这个问题，传统的解决办法，是收集更多数据，对模型进行重新训练或微调。但这样的做法往往存在一个现实难题：</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">首先，很多时候并没有更高质量的新数据可用；其次，就算训练了，也常常出现“打地鼠”式的问题——优化了一个点，另一个原本表现不错的地方反而出了问题。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">于是，研究团队换了一个思路：与其一遍遍喂它数据、帮它改模型，不如教会它怎么反思。只要让AI掌握“怎么从错误中总结经验、改进自己”的方法，它在面对不同任务时，就能逐步自行进化。用通俗的话说，就是不再一味“灌知识”，而是教它“怎么学”。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">经过测试，研究人员惊喜地发现，这种方法并不需要准备额外的数据，只要有一个能判断模型回答对错的简单反馈机制，AI就能启动自我提升的过程。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这个方法一共包含三个步骤，就像标题里写的那样：反思、重试和奖励。其实跟人类的学习过程非常像，我来给大家解释一下。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第一步，反思。</b>当模型在某个任务上第一次失败时，系统不会直接结束，而是让它先生成一段自我反思的内容，分析自己到底哪里出了问题。就像学生考试答错题后，会问自己：“我哪一步想错了？是不是公式用错了？”这一环节的核心目的，是让AI开始自我觉察，并意识到错误的原因。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第二步，重试。</b>这时候，AI模型会带着刚才的反思内容，再去尝试完成同一个任务。就像学生在弄明白上次哪里出错后，再去解同一类题目，就更容易成功。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第三步，奖励。</b>如果模型在第二次尝试中成功完成了任务，系统就会对它在“反思阶段”所生成的内容进行奖励。这里的“奖励”并不是我们理解中的发红包，而是一种强化学习技术。简单来说，就是通过调整模型参数，让它更偏向于那些曾经带来正面结果的反思方式。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">你可以把这个过程想象成一个老师在表扬学生：当学生通过反思改正了错误，终于做对了一道难题，老师会说：“你的反思很有帮助，继续保持下去，你的数学会越来越好。”注意，老师夸奖的不是解题方法本身，而是“反思”这一学习策略。所以学生就会知道，反思是有效果的，遇到问题的时候，就应该用这种方式来解决。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">所以这个机制的创新点就在于：研究人员奖励的并不是模型最后给出的正确答案，而是它中间生成的“反思过程”。这样的训练方式，让模型不再依赖死记硬背某个问题的答案，而是逐渐学会了一种通用的、自我纠错和自我提升的能力。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">而且研究团队不是光讲概念，他们还做了两个实验，来实际验证这个机制的有效性。这两个实验对于AI来说都不算简单，一个是函数调用，一个是数学方程求解，都属于具有挑战性、但又能够清晰判断对错的任务类型。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">第一个任务是函数调用，大家知道传统技术开发需要对接各种API接口，要填入各种参数。这个任务就是看AI能不能正确地调用，这不同于那种没有标准答案的写作任务，调用API，成功与否，判断标准非常明确。实验团队在多种规模大小的模型上都做了实验，测试了这种机制，例如从15亿参数的小模型到72亿参数的模型不等。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">实现效果非常令人惊叹。一个只有15亿参数的阿里千问小模型，在这个任务上，一次就答对的概率只有大约32.6%，但是经过今天介绍的这个反思训练后，第一次尝试的准确率就跃升到了48.6%，提升了16个百分点。如果允许它利用自己的反思再尝试一次，第二次的成功率就达到了52.9%，这相比原始能力提高了20多个百分点。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">第二个任务是数学方程求解，比函数调用更困难得多。实验中，15亿参数的模型在第一次尝试时，正确率只有6%，几乎等于纯靠蒙的水平，就好比初中数学100分满分只考了个6分。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">但当模型引入“反思机制”训练后，第一次尝试的正确率跃升到了34.9%，已经是一个质的飞跃。如果再让它根据第一次的反思重试一遍，第二次的成功率更是提升到45%。从最初的6%到最后的45%，这个跨度就像从不及格一路提升到接近及格线。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">还有一个更惊人的发现是，经过这种学习方法训练的小模型，在能力上超过了参数量比自己大十倍的更高级模型。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">研究团队同样使用了千问的70亿参数模型进行训练，结果发现，在这两个任务上，学会“反思”的70亿模型，表现都超过了不会反思的720亿模型。要知道，这两个模型都属于阿里千问系列。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这就像一个经过良好学习方法训练的高中生，在某些难题上，反而能打败知识储备多出十倍、但缺乏方法的博士生。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这个发现的现实意义在于，对于某些任务来说，并不一定非得依赖超大规模模型，<b>如果能优化训练方式，小模型不仅节省成本，也能具备很强的能力。</b></p><div data-module-type="custom" class="split" style="z-index: 40; position: relative;"></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这篇论文的内容我就先讲到这里。接下来，我来聊聊，我们普通用户怎么借鉴这种方法，来更好地提升自己使用AI的效果。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">首先，我观察到身边有一些同事在使用AI工具时，往往只进行一轮对话：给AI发一个任务，等它完成后就结束了。有时即便AI明显给出了错误答案，回应也只是简单一句“错了，再试一次”。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">但按照这篇论文的启发，我们其实可以<b>稍微调整一下话术</b>，比如说：“你的答案可能有问题，请分析一下哪里出错了，然后再重新回答一遍。”</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">其次，在一些具体场景下，我们可以<b>给AI提供更明确的反思方向。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">比如在做商业决策分析时，读完AI的第一轮回答后，你可以补充说：“你的分析似乎忽略了市场风险因素，请重新考虑并补充完整。”当然，这种方式前提是你自己能敏锐地识别出回答中的问题。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">类似的反思提示词还有很多，例如：</p><ul data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><li>“请检查一下你的推理过程，找出可能的逻辑漏洞。”</li><li>“分析一下你刚才的回答哪些地方可能不够准确。”</li><li>“如果让你重新回答这个问题，你会怎么改进？”</li><li>“你觉得你的答案已经完全满足问题要求了吗？请详细说明。”</li></ul><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">最后，我想分享一个我偶尔会用的小技巧，它和本文介绍的“反思机制”有异曲同工之妙。我给它起了个名字，叫做 “PUA大法”。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这个方法尤其适用于那些重要且复杂的任务，比如撰写竞品分析报告或者调研文档。我的做法是，先准备好三到四个表现稳定的大模型，比如从ChatGPT、Claude、DeepSeek、豆包、Kimi中挑选几个。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我个人的习惯是：先把任务描述清楚，然后分别让豆包、Kimi和DeepSeek先各自完成一次回答。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">接下来，我会打开ChatGPT，对它说：</p><div data-module-type="custom" class="original-block-quote" style="z-index: 40; position: relative;"><blockquote data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line;">“我正在完成一个任务，任务内容是……我已经请三个AI助手分别作答。现在你是评审官，请你根据任务的特点，制定一套100分制的评卷规则，然后分别对这三个助手的答案打分，并详细说明你的评分理由。”<br></blockquote></div> <!----> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">接下来，我就会把其他几个AI的回答一个个发给ChatGPT。这时它会先搭建一套评分标准，再对其他AI的回答进行打分和点评，比如给出85分、87分之类的分数，并详细解释打分理由。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">然后，我就会开始“PUA”它，对它说：</p><div data-module-type="custom" class="original-block-quote" style="z-index: 40; position: relative;"><blockquote data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line;">“你既然这么懂，那你自己来答一遍这个问题看看？”<br></blockquote></div> <!----> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">它会乖乖照做，答完后，我继续追问：</p><div data-module-type="custom" class="original-block-quote" style="z-index: 40; position: relative;"><blockquote data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line;">“那你就按你刚才的评分规则，对你自己的回答也打个分，并说明理由。”<br></blockquote></div> <!----> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">它通常会开始进行所谓的“公正打分”和自我评价——但你会发现，它几乎每次都比给其他AI打的分数高，一般会打个90到95分之间。哪怕这样，我也不会放过它，还要继续追问：</p><div data-module-type="custom" class="original-block-quote" style="z-index: 40; position: relative;"><blockquote data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line;">“那你这剩下的几分是扣在哪里了？好好想想，再改一遍。”<br></blockquote></div> <!----> <!----><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">当然，它最后输出的结果是不是满分作品，其实并不重要。但在这个过程中，往往会冒出很多新思路和新角度，对我们人类来说是很有启发的。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这个方法其实很简单，说到底，可能还是被我初中数学老师“深刻启发”过。当年他那种高压反思式教学，让我一度对数学敬而远之。不过还好，现在的AI没有情绪，不会反抗，我们可以尽情用“PUA语气”去激发它的智力潜力。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">好，最后我来做个预告，6月末7月初，我跟着得到同学非常熟悉的教育专家沈祖芸老师来到了美国，实地参访几所教育创新学校，同时还会去参加由国际教育技术协会等权威组织主办的全球教育峰会，接下来几天，我会把所见所闻、受到的启发，在接下来一周的广播站里跟大家分享，期待你的关注。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">今天广播就到这里。如果你觉得有帮助，欢迎分享转发给你的朋友。明天咱们接着聊AI。</p><div data-module-type="custom" class="original-block-quote" style="z-index: 40; position: relative;"><blockquote data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line;">论文链接地址：<br>https://arxiv.org/pdf/2505.24726</blockquote></div> <!----> <!----><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025062815/1880224819765649084/062815.png" class="big-image"> <!----></figure> <!----><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto;"></div></div><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto;"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div></div><svg style="z-index: 20; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"></svg><svg style="z-index: 10; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"><line x1="437.703125" y1="7533.8125" x2="72.5" y2="7533.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="633.3125" y1="7603.8125" x2="30.5" y2="7603.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="447.5" y1="7655.8125" x2="-5.5" y2="7655.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="7725.8125" x2="30.5" y2="7725.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="90.40625" y1="7777.8125" x2="30.5" y2="7777.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="627.390625" y1="6747.8125" x2="202.5" y2="6747.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="629.3125" y1="6469.8125" x2="39.5" y2="6469.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="6241.8125" x2="778.34375" y2="6241.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="682.84375" y1="6293.8125" x2="-5.5" y2="6293.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.515625" y1="6065.8125" x2="778.46875" y2="6065.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="782.40625" y1="6117.8125" x2="-5.5" y2="6117.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="5349.8125" x2="-5.5" y2="5349.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="5401.8125" x2="-5.5" y2="5401.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="525.5" y1="5453.8125" x2="-5.5" y2="5453.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="3875.8125" x2="47.421875" y2="3875.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="3927.8125" x2="-5.5" y2="3927.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="3979.8125" x2="-5.5" y2="3979.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="239.5" y1="4031.8125" x2="-5.5" y2="4031.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="190.78125" y1="1125.8125" x2="179.765625" y2="1125.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.515625" y1="1125.8125" x2="179.78125" y2="1125.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="122.5" y1="1177.8125" x2="-5.5" y2="1177.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="2287.8125" x2="-5.5" y2="2287.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="2339.8125" x2="-5.5" y2="2339.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="213.5" y1="2391.8125" x2="-5.5" y2="2391.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="2453.8125" x2="-5.5" y2="2453.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="2505.8125" x2="-5.5" y2="2505.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="825.5" y1="2557.8125" x2="-5.5" y2="2557.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="461.109375" y1="2609.8125" x2="-5.5" y2="2609.8125" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line></svg><div style="position: absolute; width: max-content; text-align: center; line-height: 0; z-index: 50; transform: translate3d(-50%, -100%, 0px); transition: transform 0.2s, opacity 0.2s; visibility: hidden; opacity: 0;"><div class="em-menu" style="font-size: 12px; background-color: rgb(38, 38, 38); border-radius: 6px; color: rgb(221, 221, 221); border: 0px; display: inline-block; padding: 14px 5px; margin: auto; height: 66px; line-height: 66px; cursor: pointer;"><span class="em-menu-item" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>写笔记</span><span class="em-menu-item em-menu-item-select" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>划线</span><span class="em-menu-item em-menu-item-highlight" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-delete-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>删除划线</span><span class="em-menu-item em-menu-item-copy" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-copy" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>复制</span></div><div class="em-menu-triangle" style="margin: -1px auto 10px; border-top: 8px solid rgb(38, 38, 38); border-right: 8px solid transparent; border-left: 8px solid transparent; width: 0px; height: 0px;"></div></div></div></div></div>

<div class="article-time-info iget-common-c3 iget-common-f4"><!----> <div class="article-publish-time">
                  首次发布: 2025年6月29日 
                </div></div>
</body>
</html>
<!doctype html>
<html lang="zh-Hant">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>31 重复博弈1：重复次数会怎样改变博弈结果？</title>
</head>
<body>
<div class="article-cover-wrap"><img src="https://piccdn3.umiwi.com/img/202503/27/202503271006269616766576.jpeg"> <!----> <!----></div>

<div class="article-title iget-common-c1" style="-webkit-box-orient: vertical;">
    31 重复博弈1：重复次数会怎样改变博弈结果？
  </div>

<div class="article-info"><div class="author"><img src="https://piccdn3.umiwi.com/img/202502/26/202502260400566644345891.jpeg"> <span class="course-title iget-common-c3 iget-common-f4">
        蒋文华·博弈论50讲
      </span></div> <span class="article-publish-time iget-common-c3 iget-common-f4">
      2025年3月28日 
    </span></div>

<div class="article-body"><div class="iget_rich-text-panel--container iget_rich-text-panel__large"><div class="editor-show" style="user-select: none; position: relative;"><div class="dd-audio" data-module-type="custom" style="z-index: 40; position: relative;"><div class="dd-audio-player iget-common-b7"><div class="dd-audio-info"><button class="dd-audio-icon iget-common-b10"><span class="iconfont iget-common-f4 iget-icon-play"></span></button> <div class="dd-audio-block iget-common-c2 iget-common-f5"><span class="audio-title" style="-webkit-box-orient: vertical;">31-重复博弈1.mp3</span> <span class="audio-duration iget-common-c3 iget-common-f6">
          15分49秒
        </span></div></div></div> <div class="audio-tips iget-common-f4 iget-common-c3">
    宝木AI 转述
  </div></div><h2 class="letter" data-module-type="custom" style="z-index: 40; position: relative;"><span data-text-node="1">Lee，你好</span></h2><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">欢迎来到博弈论课，我是蒋文华。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">今天这一讲，我们要来学一类特殊的动态博弈——重复博弈。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">顾名思义，重复博弈就是相同结构的博弈重复多次。最简单的例子，同样是买一斤香蕉，火车站门口的流动商贩跟你之间，就接近单次博弈。而同样的交易挪到小区门口，就变成了重复博弈，因为他会跟你反复打交道。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">现实中的博弈，既有大量的一锤子买卖，也有大量重复博弈，学习重复博弈能让我们在现实世界中，结合时间的维度，做出更明智、更具战略眼光的选择。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">那具体来说，“重复”会怎样改变参与者的决策考量，以及一旦博弈重复起来后，怎么寻找新的纳什均衡？我们这一讲就来解决这个问题。</p><div class="article-header header-1" data-module-type="custom" style="z-index: 40; position: relative;"><span data-text-node="1">重复博弈的三个基本特征</span></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">在寻找均衡解之前，我们先来搞懂究竟什么是重复博弈。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">重复博弈，听起来很简单，就是重复相同的博弈。但其实，现实中很多人对这种博弈理解得都有偏差。比如，象棋中轮流走子，是不是重复博弈呢？答案是，不属于。因为每一步面对的决策问题在变化，无法简单看作同一局游戏的重复。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">真正的重复博弈有3个基本特点。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>先看第一个特点，重复博弈中各阶段博弈结构完全相同，前一个阶段博弈并不改变后一个阶段的博弈结构。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">开头我们提到，重复博弈是一种特殊的动态博弈。重复博弈的这个特点是相对于其它动态博弈来说的。动态博弈由不同阶段的博弈串联而成，但每个阶段参与者所面对的博弈局面，一般会因为对手的选择而不断变化。重复博弈则不同，每阶段博弈的局面和之前的完全相同。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">比如，我们上一讲讲的要挟诉讼就是动态博弈。被告是不是接受私了，接下来原告面临的局面是不一样的。被告接受私了，博弈就结束了，但如果被告拒绝私了，原告要决定是继续起诉，还是撤诉。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">而在典型的重复博弈，比如重复囚徒困境中，前后两次博弈，双方的选项、预期收益是完全一样的。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>再看第二个特点，参与者的历史行动完全可观测。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这有点类似电商平台可以记录商家所有的好评和差评，老用户也好，新用户也好，看过评价之后都能更好地决定要不要在他们家下单。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">用博弈论的话来讲，这就意味着参与者过去的行为，会成为对方未来与他博弈的决策依据。反过来，如果博弈的历史不可以观测，那么哪怕一个博弈重复发生，也还是相当于多个独立的单次博弈。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>最后再来看第三个特点，参与者追求的是所有阶段收益的总和最大，而非单次博弈的眼前利益最大。</b>当然，因为有时间因素，这里有个贴现值的问题。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这也就意味着，即使短期要支付成本，但只要长期收益贴现后总收益更高，那也是更优策略。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">总之，重复博弈中，每个参与者后续阶段的决策，取决于之前阶段对方的行为。这样一来，每个参与者都有机会让背叛者得到惩罚，让合作者获得回报，从而影响每个参与者当下的选择。</p><div class="article-header header-1" data-module-type="custom" style="z-index: 40; position: relative;"><span data-text-node="1">重复博弈纳什均衡的求解</span></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">讲完了重复博弈的特点，接下来我们来看，重复博弈中怎么寻找新的纳什均衡。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>首先我们要说的是，并不是所有的博弈，重复之后结果都会发生变化。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">有很多博弈，重复和不重复是没有差别的，所以纳什均衡也没有变，比如石头剪子布和智猪博弈。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">在石头剪子布博弈中，不管是1次也好，重复100次也好，你我出石头、剪子和布的概率每次都是应该是三分之一，这是这个博弈的混合策略纳什均衡，双方的期望收益完全相等，博弈次数不影响均衡结果。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">在智猪博弈中，我们可以设想大猪想要通过惩罚机制，改变小猪的行为，例如威胁“这次我就是不按，看谁撑不住”。然而，由于小猪去按按钮，就要承担按按钮的成本，他反倒会更饿，相当于是净损失，所以小猪无论如何也不会去按。大猪的威胁根本没有用。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">但是，有一些博弈，一旦重复，博弈结果就会发生变化。这类博弈的共同特点是，<b>参与者在重复互动中，能利用“将来”的收益来激励或者惩罚对方。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">比如在囚徒困境中，你这次可以选择背叛，占到便宜，让我多坐了几年牢；但是下次，我会背叛你，让你多坐牢。反过来，如果你这次选择合作，我下次也可以继续和你合作，这样双方的收益显然是更大的。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">再比如蜈蚣博弈中，如果只博弈一次，你担心我后续的背叛，你很可能会一上来就直接背叛。但是，你也完全可以选择合作，来激励我的合作。我看到你选择合作后，我也会继续合作。因为我也知道我们下次还要继续博弈。除非你接下去选择背叛，我才会在下次提前背叛。这样一来，因为有了以后的长远利益，双方就有可能每次都一直玩到总收益最大为止。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>关于重复博弈的纳什均衡，第二点要说的是，重复次数是有限还是无限，也会影响博弈的结果。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">一般来讲，重复会改变均衡结果的博弈，我们仍然需要分两种情况来讨论，一种情况是博弈次数有限，一种情况是博弈次数无限。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">先说博弈次数有限的情况。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">如果重复次数是有限的，并且具体的次数是双方的共同知识，我们基本可以把重复博弈当做一般的动态博弈来分析。使用的方法，依然是逆向归纳法。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我们拿重复囚徒困境举例子。不管重复多少次，博弈的最后一次，其实都相当于单次的囚徒困境。既然双方都清楚，这次之后，没有下次了，那么，最后一次双方都会选择背叛。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">再往前推，既然双方都知道最后一次大家都会选择背叛，那么在倒数第二次双方也肯定会选择背叛，因为反正下一次大家也没有机会报复了。这么着，逆向传导到第一次，结果就是双方一开始就会选择背叛。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这说明，在有限次数的重复博弈中，均衡结果并没有发生变化。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">再说博弈次数无限的情况，或者虽然实际是有限的，但每个参与者并不知道何时会结束的情况。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这意味着，参与者的背叛会带来无限次的报复，反过来参与者的合作，也有可能会带来无限次的奖励。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">由此，合作带来的持续收益可能超过背叛的短期收益，每次都背叛未必是一个对自己最有利的选择。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">理论上来讲，要找到无限重复博弈的纳什均衡，核心方法包括三个步骤：</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第一步，构想目标结果。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这一步是根据子博弈的性质，设定希望在重复博弈中实现的目标行动路径。例如，在重复囚徒困境中，目标可以是双方永远合作；在夫妻博弈中，目标可以是轮流选择双方各自偏好的活动。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第二步，设计奖惩策略。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">也就是说，如果所有人一直遵守合作策略，则大家持续获得目标收益；但一旦有人偏离，在未来对其进行惩罚，使其未来的累积损失超过当期偏离所获收益。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第三步，策略验证。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">要验证在所设定的策略下，任何单次偏离都不会让玩家获利。这一步，可以用数学推导的方法来验证，这就比较复杂了，涉及到对贴现因子的预估，以及相关的一大堆复杂计算。现实中，也可以通过实验的方法来验证。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">显然，可以看得出来，这三个步骤当中，设计奖惩策略是核心。出于不同的风险接受能力、对手的不确定性、对未来的预期，以及参与者贴现因子不同等因素，每一个参与者都可以有不同的策略可供选择。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">接下来，我们结合阿克塞尔罗德著名的重复囚徒困境实验，来重点看一看奖惩策略的设计，在重复博弈中可以有怎样的变化。</p><div class="article-header header-1" data-module-type="custom" style="z-index: 40; position: relative;"><span data-text-node="1">奖惩策略的设计</span></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我相信，很多同学可能多少了解过著名的重复囚徒困境实验。这个实验是美国学者阿克塞尔罗德做的，他邀请各领域的聪明人，设计不同的奖惩策略，看看哪种策略最容易演化出稳定的合作。结果出人意料，竟然是看起来最简单的一报还一报策略。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">所谓一报还一报策略，就是首次选择合作，只要对方合作，下一次就选择合作，只要对方背叛，下一次就选择背叛，后续的选择始终与对方上一次的行动一样。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这个策略极其简单，并且听起来似乎是一切文化中都出现过的最朴素的处世方法，但为什么是这个最朴素的策略最后能胜出？这里我们先不展开，放到下一讲再来讲。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">除了一报还一报策略，还有其他可选策略，这些策略体现出不同参与者的行为模式：</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第一种，好人策略。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">其核心特征是，无论对方如何选择，每次都无条件合作。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">不难想象，如果我们是这种策略选择，相信对方每次都会选择背叛。这就是人们常说的“人善被人欺”。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我们应该选择善良，但一定要让我们的善良有锋芒。如果我们无原则地善良，就是纵容他人对你作恶。这样的好人其实是烂好人。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第二种，我们可以叫作曹操策略。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">跟好人策略相反，无论对方如何选择，每次都无条件背叛。这就是《三国演义》中曹操的那句名言：“宁可我负天下人，不可天下人负我！”。一般而言，曹操策略会导致对方持续背叛，除非对方刚好采用好人策略。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第三种，冷酷策略。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">冷酷策略的特征是，第一次选择合作，以好人策略开始，只要对方合作，就一直选择合作，但只要对方背叛一次，则触发永久报复，从好人策略直接调整到曹操策略。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">冷酷策略是一种介于好人策略与曹操策略之间的策略。最大特点是不给对方任何重归于好的机会，拥有强大的威慑力。换句话说，冷酷策略是最记仇的，一次受伤害，终生牢记。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">冷酷策略是我们日常生活和工作中经常会遇到的一种策略。比如一旦你借钱不还，对方就再也不会借给你了。领导给你安排一个重要任务，一旦你搞砸了，以后也就再也没机会了。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">第一次听到冷酷策略，我们的本能感觉可能是不喜欢这样的策略。谁不会犯错呢？为什么就不给个改过的机会呢？但其实，从群体的角度看，冷酷策略的存在增加了每个人的背叛成本，从而让大家享受到了更多的合作利益。这一点我还会在后续演化博弈的课程中进一步展开。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第四种，心软策略。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这个策略是第一次先选择合作，只要对方合作，就继续选择合作，可以接受对方的一次背叛，一旦对方连续两次背叛就选择永远背叛。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">相对于冷酷策略，心软策略的好处是至少给对方犯错误的机会，只要及时改正就愿意原谅对方。相伴随的坏处是总愿意给对方背叛自己的机会，这样的弱点也很容易被对方所利用。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">比如有些女孩子遇到渣男，渣男每次伤害完了后总是信誓旦旦地保证下一次再也不敢了，结果没多久又故伎重演。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;"><b>第五种，欺软怕硬策略。</b></p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">这种策略的核心特征是先发制人测试对方底线。第一步背叛，然后每走一步，估计自己合作或背叛后对方合作的概率，如果对方似乎仍然倾向于合作，则选择背叛；反之，选择合作。这种策略一旦遇到对方是好人策略，就赚大了。但如果遇到其他策略，未必有好结果。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">以上几种策略，并不是重复博弈中的全部可选策略。理论上来讲，如果博弈重复次数是无限的，每个参与者的可选策略也是无限的。而这些策略，也并非只能用在重复囚徒困境当中，也可以用在其他重复博弈中，至于哪种策略在哪种博弈中会带来纳什均衡，需要具体分析才行。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">要承认的是，理论上分析无限次重复博弈的纳什均衡虽然有一个基本框架，但这个框架依赖于对参与者的贴现因子的预估，带有很大的主观成分，并不像单次博弈分析方法那么简单好用。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">重复博弈更多地变成了一种实践的智慧。在重复博弈中，虽然每个参与者都可以选自己喜欢的策略，但是，只有经得起实践检验的策略才真正值得我们拥有。</p><div class="article-header header-1" data-module-type="custom" style="text-align: center; z-index: 40; position: relative;"><span data-text-node="1">总结</span></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">好了，我们来总结一下这一讲的内容。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">重复博弈是一种比较特殊的动态博弈。每次博弈不会改变下次博弈的结构，但每次博弈之间，存在着“利益”和“信息”上的联系。这迫使参与者需要在眼前利益和未来利益之间做抉择。</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">以“囚徒困境”为例的重复博弈，如果重复次数有限，每个参与者每次都背叛仍然是均衡结果。如果重复次数无限，每次都背叛未必是参与者能够获得最大利益的策略选择。</p><div class="article-header header-1" data-module-type="custom" style="text-align: center; z-index: 40; position: relative;"><span data-text-node="1">下节预告</span></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">预告一下一讲的内容，前面我们提到，在阿克塞尔罗德的重复囚徒困境实验中，是一报还一报策略最终取胜，这个策略的优势到底从哪里来？下一讲我们就来展开分析。</p><div class="article-header header-1" data-module-type="custom" style="text-align: center; z-index: 40; position: relative;"><span data-text-node="1">思考题</span></div><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">最后给你留一道思考题，在以往的生活和工作经历中，你是否碰到过有人采用“冷酷策略”和你博弈，你是怎么应对的？</p><p data-module-type="internal" data-text-node="1" style="text-align: left; white-space: pre-line; z-index: 40; position: relative;">我是蒋文华，我们下节课见。</p><div class="elite-module" data-module-type="custom" style="z-index: 40; position: relative;"><div class="elite-control"><div class="elite-title">
      划重点
    </div> <div class="iconfont iget-icon-add-book elite-add-to-note iget-common-f5 iget-common-c9 iget-common-b10 cursorPointer">
      添加到笔记
    </div></div> <div class="elite-content"><div class="bg"><div class="wrapper"><div class="pens"></div> <div class="blackboard"><div class="content" style="font-size: 26px; line-height: 52px;"><span style="white-space: pre-line;">1、重复博弈是一种比较特殊的动态博弈，每次博弈不会改变下次博弈的结构，但每次博弈之间，存在着“利益”和“信息”上的联系。这迫使参与者需要在眼前利益和未来利益之间做抉择。<br>2、以“囚徒困境”为例的重复博弈，如果重复次数有限，每个参与者每次都背叛仍然是均衡结果。如果重复次数无限，每次都背叛未必是参与者能够获得最大利益的策略选择。</span></div></div></div></div></div></div><figure data-module-type="custom" style="z-index: 40; position: relative;"><img src="https://piccdn2.umiwi.com/uploader/image/ddarticle/2025032718/1871607256722747768/032718.jpeg" class="big-image"> <!----></figure> <!----><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto;"></div></div><div style="user-select: none; z-index: 30; transition: top 0.1s, left 0.1s; display: none; position: absolute;"><div style="border-radius: 50%; margin: auto;"></div><div style="margin: auto; background-color: rgb(255, 107, 0);"></div><div style="border-radius: 50%; margin: auto; background-color: rgb(255, 107, 0);"></div></div><svg style="z-index: 20; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"></svg><svg style="z-index: 10; pointer-events: none; width: 100%; height: 100%; position: absolute; top: 0px; left: 0px; overflow: visible;"><line x1="664.1640625" y1="5657.375" x2="205.4296875" y2="5657.375" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="1006.375" y1="1959.375" x2="152.7265625" y2="1959.375" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="239.375" y1="2011.375" x2="-5.375" y2="2011.375" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="1006.375" y1="1233.375" x2="574.3515625" y2="1233.375" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="1006.375" y1="1285.375" x2="-5.375" y2="1285.375" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="1006.375" y1="1337.375" x2="-5.375" y2="1337.375" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="135.375" y1="1389.375" x2="-5.375" y2="1389.375" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><rect x="105.375" y="1388.375" rx="2" ry="2" width="30" height="16" fill="rgb(231,130,95)"></rect><text x="130.375" y="1392.375" dominant-baseline="hanging" text-anchor="end" font-size="10" fill="#fff" class="em-highlight-tag-text">笔记</text><line x1="359.0703125" y1="1057.375" x2="72.625" y2="1057.375" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="1006.375" y1="365.375" x2="130.0390625" y2="365.375" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="1006.375" y1="417.375" x2="-5.375" y2="417.375" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><line x1="525.375" y1="469.375" x2="-5.375" y2="469.375" style="stroke: rgb(231, 130, 95); stroke-width: 1;"></line><rect x="495.375" y="468.375" rx="2" ry="2" width="30" height="16" fill="rgb(231,130,95)"></rect><text x="520.375" y="472.375" dominant-baseline="hanging" text-anchor="end" font-size="10" fill="#fff" class="em-highlight-tag-text">笔记</text></svg><div style="position: absolute; width: max-content; text-align: center; line-height: 0; z-index: 50; transform: translate3d(-50%, -100%, 0px); transition: transform 0.2s, opacity 0.2s; visibility: hidden; opacity: 0;"><div class="em-menu" style="font-size: 12px; background-color: rgb(38, 38, 38); border-radius: 6px; color: rgb(221, 221, 221); border: 0px; display: inline-block; padding: 14px 5px; margin: auto; height: 66px; line-height: 66px; cursor: pointer;"><span class="em-menu-item" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>写笔记</span><span class="em-menu-item em-menu-item-select" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-note-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>划线</span><span class="em-menu-item em-menu-item-highlight" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-delete-line" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>删除划线</span><span class="em-menu-item em-menu-item-copy" style="line-height: 1.24rem; padding: 0px 15px; color: rgb(221, 221, 221); display: inline-block;"><span class="em-menu-item-icon iconfont iget-icon-copy" style="display: block; color: rgb(204, 204, 204); font-size: 20px; margin-bottom: 2px;"></span>复制</span></div><div class="em-menu-triangle" style="margin: -1px auto 10px; border-top: 8px solid rgb(38, 38, 38); border-right: 8px solid transparent; border-left: 8px solid transparent; width: 0px; height: 0px;"></div></div></div></div></div>

<div class="article-time-info iget-common-c3 iget-common-f4"><!----> <div class="article-publish-time">
                  首次发布: 2025年3月28日 
                </div></div>
</body>
</html>